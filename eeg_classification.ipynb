{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ryoii\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.fft as fft\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision\n",
    "import torchaudio\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import time, sys, os\n",
    "\n",
    "from utils import MindBigData, GetDataSet, GetDataLoaders, GetDataLoadersEEGImages, GetDataAndPreProcess\n",
    "from MultilayerBidirectionalRNN import MultilayerBidirectionalRNN\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load EEG data from specified data path, with specified number of samples per digit.\n",
    "- GetDataSet : standardization, min-max scaling within std \n",
    "    x : 振幅 in microVolts\n",
    "    y : target digit\n",
    "- Preprocess : butterworth filter(highpass 0.1Hz + 平滑化),\n",
    " notch filter(ノイズ除去 50Hz), trim first 32 samples\n",
    "\"\"\"\n",
    "dataName = \"EP/EP1.01.txt\"\n",
    "# dataName = \"MUSE/MU.txt\"\n",
    "dataPath = os.path.join(os.path.dirname(os.getcwd()), dataName)\n",
    "\n",
    "x_raw, x_preprocessed, x_reconstructed, x_standardized, y = GetDataAndPreProcess(input_file=dataPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 14, 256)\n",
      "(50000, 14, 224)\n",
      "(50000, 14, 224)\n",
      "(50000, 14, 224)\n"
     ]
    }
   ],
   "source": [
    "# (trial, channel, data points)\n",
    "print(x_raw.shape)\n",
    "print(x_preprocessed.shape)\n",
    "print(x_reconstructed.shape)\n",
    "print(x_standardized.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prepare dataloaders 75%:15%:10%\n",
    "\"\"\"\n",
    "train_loader_raw, valid_loader_raw, test_loader_raw = GetDataLoaders(x_raw, y, batch_size=64)\n",
    "train_loader_preprocessed, valid_loader_preprocessed, test_loader_preprocessed = GetDataLoaders(x_preprocessed, y, batch_size=64)\n",
    "train_loader_reconstructed, valid_loader_reconstructed, test_loader_reconstructed = GetDataLoaders(x_reconstructed, y, batch_size=64)\n",
    "train_loader_standardized, valid_loader_standardized, test_loader_standardized = GetDataLoaders(x_standardized, y, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 14, 256), found shape=(None, 14, 224)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m MultilayerBidirectionalRNN(input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m256\u001b[39m), num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Train the model and save the best one\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader_standardized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader_standardized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_model.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Evaluate the best model on the test set\u001b[39;00m\n\u001b[0;32m      8\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_loader_standardized)\n",
      "File \u001b[1;32mc:\\Users\\ryoii\\Desktop\\Research\\digit_classification_Vie\\MultilayerBidirectionalRNN.py:76\u001b[0m, in \u001b[0;36mMultilayerBidirectionalRNN.train\u001b[1;34m(self, train_loader, batch_size, epochs, validation_data, checkpoint_path)\u001b[0m\n\u001b[0;32m     73\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [checkpoint]\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[1;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    250\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"functional\" is incompatible with the layer: expected shape=(None, 14, 256), found shape=(None, 14, 224)"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = MultilayerBidirectionalRNN(input_shape=(14, 256), num_classes=10)\n",
    "\n",
    "# Train the model and save the best one\n",
    "model.train(train_loader_standardized, validation_loader=valid_loader_standardized, epochs=10, checkpoint_path='best_model.keras')\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_loader_standardized)\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 2 signals with their labels\n",
    "data_iter = iter(train_loader_raw)\n",
    "inputs, labels = next(data_iter)\n",
    "EEGChannel = [\"AF3\", \"F7\", \"F3\", \"FC5\", \"T7\", \"P7\", \"O1\", \"O2\", \"P8\", \"T8\", \"FC6\", \"F4\", \"F8\", \"AF4\"]\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "for i in range(1):\n",
    "    for j in range(14):\n",
    "        ax = fig.add_subplot(14, 2, i + 1 + 2 * j)\n",
    "        if (j == 0):\n",
    "            ax.set_title(\n",
    "                'Raw : digit seen by patient: ' + str(labels[i].item()))  # .item() gets the value contained in a tensor\n",
    "        ax.plot(inputs[i][j])\n",
    "        ax.set_xlabel('samples')\n",
    "        ax.set_ylabel(EEGChannel[j])\n",
    "        ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 2 signals with their labels\n",
    "data_iter = iter(train_loader_preprocessed)\n",
    "inputs, labels = next(data_iter)\n",
    "EEGChannel = [\"AF3\", \"F7\", \"F3\", \"FC5\", \"T7\", \"P7\", \"O1\", \"O2\", \"P8\", \"T8\", \"FC6\", \"F4\", \"F8\", \"AF4\"]\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "for i in range(1):\n",
    "    for j in range(14):\n",
    "        ax = fig.add_subplot(14, 2, i + 1 + 2 * j)\n",
    "        if (j == 0):\n",
    "            ax.set_title(\n",
    "                'Preprocessed : digit seen by patient: ' + str(labels[i].item()))  # .item() gets the value contained in a tensor\n",
    "        ax.plot(inputs[i][j])\n",
    "        ax.set_xlabel('samples')\n",
    "        ax.set_ylabel(EEGChannel[j])\n",
    "        ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 2 signals with their labels\n",
    "data_iter = iter(train_loader_reconstructed)\n",
    "inputs, labels = next(data_iter)\n",
    "EEGChannel = [\"AF3\", \"F7\", \"F3\", \"FC5\", \"T7\", \"P7\", \"O1\", \"O2\", \"P8\", \"T8\", \"FC6\", \"F4\", \"F8\", \"AF4\"]\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "for i in range(1):\n",
    "    for j in range(14):\n",
    "        ax = fig.add_subplot(14, 2, i + 1 + 2 * j)\n",
    "        if (j == 0):\n",
    "            ax.set_title(\n",
    "                'reconstructed : digit seen by patient: ' + str(labels[i].item()))  # .item() gets the value contained in a tensor\n",
    "        ax.plot(inputs[i][j])\n",
    "        ax.set_xlabel('samples')\n",
    "        ax.set_ylabel(EEGChannel[j])\n",
    "        ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display 2 signals with their labels\n",
    "data_iter = iter(train_loader_standardized)\n",
    "inputs, labels = next(data_iter)\n",
    "EEGChannel = [\"AF3\", \"F7\", \"F3\", \"FC5\", \"T7\", \"P7\", \"O1\", \"O2\", \"P8\", \"T8\", \"FC6\", \"F4\", \"F8\", \"AF4\"]\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "for i in range(1):\n",
    "    for j in range(14):\n",
    "        ax = fig.add_subplot(14, 2, i + 1 + 2 * j)\n",
    "        if (j == 0):\n",
    "            ax.set_title(\n",
    "                'standardized : digit seen by patient: ' + str(labels[i].item()))  # .item() gets the value contained in a tensor\n",
    "        ax.plot(inputs[i][j])\n",
    "        ax.set_xlabel('samples')\n",
    "        ax.set_ylabel(EEGChannel[j])\n",
    "        ax.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
